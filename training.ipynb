{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "352dc02e-02c0-488f-9a49-63870441af7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>No-show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T18:38:08Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-29T16:08:27Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:19:04Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T17:29:31Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:07:23Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientId  AppointmentID Gender          ScheduledDay  \\\n",
       "0  2.987250e+13        5642903      F  2016-04-29T18:38:08Z   \n",
       "1  5.589978e+14        5642503      M  2016-04-29T16:08:27Z   \n",
       "2  4.262962e+12        5642549      F  2016-04-29T16:19:04Z   \n",
       "3  8.679512e+11        5642828      F  2016-04-29T17:29:31Z   \n",
       "4  8.841186e+12        5642494      F  2016-04-29T16:07:23Z   \n",
       "\n",
       "         AppointmentDay  Age      Neighbourhood  Scholarship  Hipertension  \\\n",
       "0  2016-04-29T00:00:00Z   62    JARDIM DA PENHA            0             1   \n",
       "1  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             0   \n",
       "2  2016-04-29T00:00:00Z   62      MATA DA PRAIA            0             0   \n",
       "3  2016-04-29T00:00:00Z    8  PONTAL DE CAMBURI            0             0   \n",
       "4  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             1   \n",
       "\n",
       "   Diabetes  Alcoholism  Handcap  SMS_received No-show  \n",
       "0         0           0        0             0      No  \n",
       "1         0           0        0             0      No  \n",
       "2         0           0        0             0      No  \n",
       "3         0           0        0             0      No  \n",
       "4         1           0        0             0      No  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from google.cloud import storage\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='tron-argolis', token='/home/sockcop/k/k.json')\n",
    "\n",
    "with fs.open('gs://tron-argolis-dataset/kagglev2-may-2016.csv') as f:\n",
    "    gcs_df = pd.read_csv(f)\n",
    "\n",
    "gcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24e92cad-ff9e-46c5-a9a4-a18d5918779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "110522    False\n",
      "110523    False\n",
      "110524    False\n",
      "110525    False\n",
      "110526    False\n",
      "Name: No-show, Length: 110527, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(gcs_df['No-show'] == 'Yes')\n",
    "gcs_df['output_label'] = (gcs_df['No-show'] == 'Yes').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93f4a9e7-d11d-4491-9a01-29dd8d4d4939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        NaT\n",
      "1        NaT\n",
      "2        NaT\n",
      "3        NaT\n",
      "4        NaT\n",
      "          ..\n",
      "110522   NaT\n",
      "110523   NaT\n",
      "110524   NaT\n",
      "110525   NaT\n",
      "110526   NaT\n",
      "Name: ScheduledDay, Length: 110527, dtype: datetime64[ns]\n",
      "0        NaT\n",
      "1        NaT\n",
      "2        NaT\n",
      "3        NaT\n",
      "4        NaT\n",
      "          ..\n",
      "110522   NaT\n",
      "110523   NaT\n",
      "110524   NaT\n",
      "110525   NaT\n",
      "110526   NaT\n",
      "Name: ScheduledDay, Length: 110527, dtype: datetime64[ns]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "missing ScheduledDay dates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33368/3393228734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgcs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ScheduledDay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ScheduledDay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y-%m-%dT%H-%M-%SZ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ScheduledDay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mgcs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScheduledDay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'missing ScheduledDay dates'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: missing ScheduledDay dates"
     ]
    }
   ],
   "source": [
    "print(gcs_df['ScheduledDay'])\n",
    "gcs_df['ScheduledDay'] = pd.to_datetime(gcs_df['ScheduledDay'], format='%Y-%m-%dT%H-%M-%SZ', errors='coerce')\n",
    "print(gcs_df['ScheduledDay'])\n",
    "assert gcs_df.ScheduledDay.isnull().sum() == 0, 'missing ScheduledDay dates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e87dbfa4-903a-438e-a877-1fa7568c42eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "          ..\n",
      "110522   NaN\n",
      "110523   NaN\n",
      "110524   NaN\n",
      "110525   NaN\n",
      "110526   NaN\n",
      "Name: ScheduledDay, Length: 110527, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(gcs_df['ScheduledDay'].dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3dac344a-de16-4ac3-a37c-99d39c2b0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20193255946510807"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_prev(y):\n",
    "    return (sum(y)/len(y))\n",
    "\n",
    "calc_prev(gcs_df.output_label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28458f17-990b-475f-94b8-36e70b7820e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38568\n"
     ]
    }
   ],
   "source": [
    "print((gcs_df['ScheduledDay']>gcs_df['AppointmentDay']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f30bb9c8-6831-441f-82f1-8cc299399496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.v2.dsl import component, Input, Output, Artifact\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/sockcop/k/k.json'\n",
    "client = kfp.Client(host='https://11f0f736521255cb-dot-us-central1.pipelines.googleusercontent.com')\n",
    "\n",
    "@component(packages_to_install=['gcsfs', 'pandas', 'numpy'])\n",
    "def data_preprocess(dataset: str, output_path: Output[Artifact]):\n",
    "    import pandas as pd\n",
    "    import numpy\n",
    "\n",
    "    df = pd.read_csv(dataset)\n",
    "    df['output_label'] = (df['No-show'] == 'Yes').astype('int')\n",
    "    df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'], \n",
    "                                          format = '%Y-%m-%dT%H:%M:%SZ', \n",
    "                                          errors = 'coerce') \n",
    "    df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'], \n",
    "                                          format = '%Y-%m-%dT%H:%M:%SZ', \n",
    "                                          errors = 'coerce')\n",
    "\n",
    "    assert df.ScheduledDay.isnull().sum() == 0, 'missing ScheduledDay dates'\n",
    "    assert df.AppointmentDay.isnull().sum() == 0, 'missing AppointmentDay dates'\n",
    "    \n",
    "    df['AppointmentDay'] = df['AppointmentDay'] +pd.Timedelta('1d') - pd.Timedelta('1s')\n",
    "    \n",
    "    df['ScheduledDay_year'] = df['ScheduledDay'].dt.year\n",
    "    df['ScheduledDay_month'] = df['ScheduledDay'].dt.month\n",
    "    df['ScheduledDay_week'] = df['ScheduledDay'].dt.week\n",
    "    df['ScheduledDay_day'] = df['ScheduledDay'].dt.day\n",
    "    df['ScheduledDay_hour'] = df['ScheduledDay'].dt.hour\n",
    "    df['ScheduledDay_minute'] = df['ScheduledDay'].dt.minute\n",
    "    df['ScheduledDay_dayofweek'] = df['ScheduledDay'].dt.dayofweek\n",
    "    \n",
    "    print('break')\n",
    "    df['AppointmentDay_year'] = df['AppointmentDay'].dt.year\n",
    "    df['AppointmentDay_month'] = df['AppointmentDay'].dt.month\n",
    "    df['AppointmentDay_week'] = df['AppointmentDay'].dt.week\n",
    "    df['AppointmentDay_day'] = df['AppointmentDay'].dt.day\n",
    "    df['AppointmentDay_hour'] = df['AppointmentDay'].dt.hour\n",
    "    df['AppointmentDay_minute'] = df['AppointmentDay'].dt.minute\n",
    "    df['AppointmentDay_dayofweek'] = df['AppointmentDay'].dt.dayofweek\n",
    "    \n",
    "    df['delta_days'] = (df['AppointmentDay']-df['ScheduledDay']).dt.total_seconds()/(60*60*24)\n",
    "    \n",
    "    df = df.sample(n = len(df), random_state = 42)\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    with open(output_path.path, 'w') as f:\n",
    "        df.to_csv(f)\n",
    "    \n",
    "@component(packages_to_install=['gcsfs', 'pandas', 'numpy', 'sklearn'])\n",
    "def training(input_path: Input[Artifact]):\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    with open(input_path.path, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    \n",
    "    col2use = ['ScheduledDay_day', \n",
    "               'ScheduledDay_hour',\n",
    "               'ScheduledDay_minute', \n",
    "               'ScheduledDay_dayofweek', \n",
    "               'AppointmentDay_day',\n",
    "               'AppointmentDay_dayofweek', \n",
    "               'delta_days']\n",
    "        \n",
    "    df_valid = df.sample(frac = 0.3, random_state = 42)\n",
    "    df_train = df.drop(df_valid.index)\n",
    "    \n",
    "    X_train = df_train[col2use].values\n",
    "    X_valid = df_valid[col2use].values\n",
    "    y_train = df_train['output_label'].values\n",
    "    y_valid = df_valid['output_label'].values\n",
    "    print('Training shapes:',X_train.shape, y_train.shape)\n",
    "    print('Validation shapes:',X_valid.shape, y_valid.shape)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf=RandomForestClassifier(max_depth=5, n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_preds = rf.predict_proba(X_train)[:,1]\n",
    "    y_train_preds = rf.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "@kfp.dsl.pipeline(name='operation')\n",
    "def pipeline_op():\n",
    "    data_prep_task = data_preprocess('gs://tron-argolis-dataset/kagglev2-may-2016.csv')\n",
    "    training_task = training(data_prep_task.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "74b062c3-157c-4e6e-843e-a7d9ec210b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sockcop/miniconda3/envs/kfp/lib/python3.7/site-packages/kfp/compiler/compiler.py:79: UserWarning: V2_COMPATIBLE execution mode is at Beta quality. Some pipeline features may not work as expected.\n",
      "  warnings.warn('V2_COMPATIBLE execution mode is at Beta quality.'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://11f0f736521255cb-dot-us-central1.pipelines.googleusercontent.com/#/experiments/details/48ef2e12-8406-4773-8eea-1909c9876633\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://11f0f736521255cb-dot-us-central1.pipelines.googleusercontent.com/#/runs/details/d44e72ee-3c93-4f66-8d92-64d24765f997\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=d44e72ee-3c93-4f66-8d92-64d24765f997)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_run_from_pipeline_func(pipeline_op, \n",
    "                                     arguments={}, \n",
    "                                     mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c8b47e63-32a3-4bd9-9f5a-2cbce7032285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/sockcop/miniconda3/envs/kfp/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=e2a35e9f3176868ed375876f50db5bcff3a27298d7ba3619b61692ae954b0915\n",
      "  Stored in directory: /home/sockcop/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.0.1 scipy-1.7.3 sklearn-0.0 threadpoolctl-3.0.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e0cde6cd-f7b4-4550-b581-6e80d7a78350",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomforestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33368/1960191325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRandomforestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomforestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomforestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c6027afa-141a-4839-92f3-bb46450aa7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "Training shapes: (77369, 7) (77369,)\n",
      "Validation shapes: (33158, 7) (33158,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sockcop/miniconda3/envs/kfp/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "/home/sockcop/miniconda3/envs/kfp/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomforestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33368/1376614981.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomforestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomforestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "    import pandas as pd\n",
    "    import numpy\n",
    "    import gcsfs\n",
    "\n",
    "    fs = gcsfs.GCSFileSystem(project='tron-argolis', token='/home/sockcop/k/k.json')\n",
    "\n",
    "    with fs.open('gs://tron-argolis-dataset/kagglev2-may-2016.csv') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    \n",
    "    df['output_label'] = (df['No-show'] == 'Yes').astype('int')\n",
    "    df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'], \n",
    "                                          format = '%Y-%m-%dT%H:%M:%SZ', \n",
    "                                          errors = 'coerce') \n",
    "    df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'], \n",
    "                                          format = '%Y-%m-%dT%H:%M:%SZ', \n",
    "                                          errors = 'coerce')\n",
    "\n",
    "    assert df.ScheduledDay.isnull().sum() == 0, 'missing ScheduledDay dates'\n",
    "    assert df.AppointmentDay.isnull().sum() == 0, 'missing AppointmentDay dates'\n",
    "    \n",
    "    df['AppointmentDay'] = df['AppointmentDay'] +pd.Timedelta('1d') - pd.Timedelta('1s')\n",
    "    \n",
    "    df['ScheduledDay_year'] = df['ScheduledDay'].dt.year\n",
    "    df['ScheduledDay_month'] = df['ScheduledDay'].dt.month\n",
    "    df['ScheduledDay_week'] = df['ScheduledDay'].dt.week\n",
    "    df['ScheduledDay_day'] = df['ScheduledDay'].dt.day\n",
    "    df['ScheduledDay_hour'] = df['ScheduledDay'].dt.hour\n",
    "    df['ScheduledDay_minute'] = df['ScheduledDay'].dt.minute\n",
    "    df['ScheduledDay_dayofweek'] = df['ScheduledDay'].dt.dayofweek\n",
    "    \n",
    "    print('break')\n",
    "    df['AppointmentDay_year'] = df['AppointmentDay'].dt.year\n",
    "    df['AppointmentDay_month'] = df['AppointmentDay'].dt.month\n",
    "    df['AppointmentDay_week'] = df['AppointmentDay'].dt.week\n",
    "    df['AppointmentDay_day'] = df['AppointmentDay'].dt.day\n",
    "    df['AppointmentDay_hour'] = df['AppointmentDay'].dt.hour\n",
    "    df['AppointmentDay_minute'] = df['AppointmentDay'].dt.minute\n",
    "    df['AppointmentDay_dayofweek'] = df['AppointmentDay'].dt.dayofweek\n",
    "    \n",
    "    df['delta_days'] = (df['AppointmentDay']-df['ScheduledDay']).dt.total_seconds()/(60*60*24)\n",
    "    \n",
    "    df = df.sample(n = len(df), random_state = 42)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    col2use = ['ScheduledDay_day', \n",
    "               'ScheduledDay_hour',\n",
    "               'ScheduledDay_minute', \n",
    "               'ScheduledDay_dayofweek', \n",
    "               'AppointmentDay_day',\n",
    "               'AppointmentDay_dayofweek', \n",
    "               'delta_days']\n",
    "        \n",
    "    df_valid = df.sample(frac = 0.3, random_state = 42)\n",
    "    df_train = df.drop(df_valid.index)\n",
    "    \n",
    "    X_train = df_train[col2use].values\n",
    "    X_valid = df_valid[col2use].values\n",
    "    y_train = df_train['output_label'].values\n",
    "    y_valid = df_valid['output_label'].values\n",
    "    print('Training shapes:',X_train.shape, y_train.shape)\n",
    "    print('Validation shapes:',X_valid.shape, y_valid.shape)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf=RandomforestClassifier(max_depth=5, n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_preds = rf.predict_proba(X_train)[:,1]\n",
    "    y_train_preds = rf.predict_proba(X_valid)[:,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3a204-c712-46f9-b8c3-325fcd90b259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kfp (ipykernel)",
   "language": "python",
   "name": "kfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
